# AdversarialTransferabilityResearch

##### Abstract:
 This project studies adversarial transferability between Classical Convolutional Neural Networks
 (CNNs) and Hybrid Quantum-Classical CNNs (HQCNNs) under gradient-based attacks, specifically
 FGSM and PGD. Adversarial examples are generated on one model type (classical or
 hybrid) and evaluated on the other to analyze cross-model vulnerability. This bidirectional
 assessment helps reveal the extent to which perturbations crafted on one architecture affect
 another. Understanding such transferability is critical in the context of grey-box and black-box
 attacks, where adversaries exploit shared weaknesses without full model access. The findings aim
 to inform the design of more robust and secure AI systems in the emerging quantum machine
 learning landscape.

:warning: **CAUTION:** :warning: Throughout this experiment number of qubits used was kept as 5, if you do wish to change it please don't forget to make this change at the top of _entanglement_circuit.py apart from entering the apt value in model_creation_factory.

 **This readme will be updated in detail on conclusion of the research.**
